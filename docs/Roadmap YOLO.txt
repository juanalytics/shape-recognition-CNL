
PATH: 
Go for Pretrained YOLO + OpenCV if you want a quick and effective solution without much training.
Only train YOLO from scratch if OpenCV struggles to classify shapes or if the pretrained YOLO model does not generalize well.

CONDA: 
# To activate this environment, use
#
#     $ conda activate yolo-env
#
# To deactivate an active environment, use
#
#     $ conda deactivate

Your GTX 1050 Ti (4GB VRAM) has limited memory, so:
Recommended batch size: 8 - 16
‚úÖ Start with batch size = 8, increase only if training runs without crashing..

üîç YOLOv8n has 225 layers.
We are going to train only in the neck and head layers
so we are fixing the first 50 layers

saving different versions of your .pt file is crucial because:
‚úÖ It allows rollback if the latest model is worse.
‚úÖ You can compare different training runs to find the best model.
‚úÖ If the training process fails or gets interrupted, you don‚Äôt lose progress.

How to Save Different Versions?
Automatically save the best model during training:
model.train(data="shapes.yaml", epochs=50, batch=8, imgsz=640, save=True)


YOLO makes it's own augmentation during training time: 
Random Contrast Adjustments
Random Hue and Saturation Changes
Gaussian Blur

But we are still going to do the following augmentations before training: 
Grayscale Conversion (5-10% of images)
Salt-and-Pepper Noise

this is because YOLO augmentation will allow to augmentate each image's collor differently. 

There are two stages in training: 
1. Stage 1 (Single Shapes + Partial Shapes) is teaching basic shape recognition.
‚úÖStart with 2,000 images in Stage 1.
‚úÖ If validation accuracy is poor, increase to 3,000.
‚úÖ Training time should remain reasonable on a GTX 1050 Ti.

2. tage 2 (Multiple Overlapping Shapes) is where more data matters most. 5,000 images may be enough if shapes are diverse.
‚úÖ Start with 5,000 images in Stage 2.
‚úÖ If validation accuracy is high, no need to go to 10,000.
‚úÖ If overfitting occurs, increase dataset size to 7,000+.

To ensure that lables to the images are properly setup, there's a script that draws the boundingboxes over the original
images, so one can visually verify that everything is generaly okay, before training, that script is: show_labeled_images.py

After training, the following command is great for manually checking the predictions with the testing set (adjusting confidence): 
yolo predict model=models/best23.pt source=D:/Repos/shape-recognition-CNL/datasets/Data2/images/test save=True save=True conf=0.5
